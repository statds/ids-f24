## Import/Export Data

This section was written by Deyu Xu, a MS student in Statistics
at the time.

### Frame
+ import files in common formats: CSV/Excel/TXT
+ import data from other sowtware
+ view data information
+ find null values
+ export data as CSV file

### Package Pandas
```python
# install the common version of pandas
pip install pandas
# install the latest version of pandas
pip install --upgrade pandas
```

### CSV files
```{python}
# use package pandas
import pandas as pd
# choose the function "read_csv"
df_csv = pd.read_csv("311_Service_request.csv")
# show the top 5 rows of data
print(df_csv.head(5))
```

### Excel files
```{python}
import pandas as pd
# choose the function "read_excel"
df_excel = pd.read_excel("311_Service_request.xlsx", engine = "openpyxl")
# print top 2 rows of the data
print(df_excel.head(2))
```

### Excel files
+ older versions of pandas
```python
df_excel = pd.read_excel("311_Service_request.xlsx", engine = "openpyxl", encoding = "utf-8")
```

### txt files
```{python}
import pandas as pd
# choose the function "read_table"
df_txt = pd.read_table("311_Service_request.txt", encoding = "utf-16")
# test the default of the fuchtion "head" 
print(df_txt.head())
```

### txt files
+ How to determine the correct encoding of a file
```{python}
import chardet
# keyword, with: Excute "open" first and the executed file object is assigned to variable"f"
with open("311_Service_request.txt", "rb") as f:
    raw_data = f.read()
    result = chardet.detect(raw_data) # Accepts one argument，a non-unicode string and returns a dictionary containing the automatically detected character encoding and a confidence level from 0 to 1.
    encoding = result["encoding"]
    print(str(encoding))
```

### Import the data from other software
+ sas7bdat files
```python
import sas7bdat
from sas7bdat import SAS7BDAT
```
+ rdata files(the suffix is .RData)
```python
import pyreadr as pr
from pyreadr import read_r
```
+ stata data(the suffix is .dta)
```python
from pandas import read_stata
```
### Import the data from other software
+ spss data(the suffix is .sav)
```python
# variables are numeric values
import pandas 
from pandas import read_spss
# variables are text
import pyreadstat 
from pyreadstat import read_sav
```
+ Matlab files
```python
import spicy.io
from spicy.io import loadmat
```
+ HDF5 files
```python
import h5py
from h5py import File
```

### Import multiple files and merge them into a new file
```{python}
# use the package globe and the package pandas
import glob 
import pandas as pd
# Set the file path
path = "/Users/xudeyu/Downloads/data"
# Merge multiple arrays
all_files = glob.glob(path+"/*.csv")
# create a list to store the data
all_data = []
# use the cycle to import all of the csv files
for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    all_data.append(df)
# Combine multiple pandas objects into one along a fixed axis using some merging method
data_merge = pd.concat(all_data, axis=0, ignore_index=True)
print(data_merge.head(2))
```

### View data information
+ View data size/dimension
```{python}
df_csv.shape
```

+ check the data type of each variable
```{python}
df_csv.dtypes
```

### View overall data information
+ View overall data information
```{python}
df_csv.info()
```

### View overall data information
+ View data description
```{python}
df_csv.describe()
```
### View overall data information
+ View names of columns
```{python}
df_csv.columns
```

### View overall data information
+ View the last 2 rows
```{python}
df_csv.tail(n = 2)
```

### View overall data information
+ Get unique values ​​of a column of data
```{python}
df_csv["Unique Key"].unique()
```

+ Get the value of a column(without deduplication)
```{python}
df_csv["Unique Key"].values
```

### Find Null Values
+ Determine whether there are missing values ​​in the data columns
```{python}
df_csv.isnull().any(axis = 0) 
```
### Find Null Values
+ Determine whether there are missing values ​​in the data rows
```{python}
df_csv.isnull().any(axis = 1)
```
### Find Null Values
+ Locate the rows with missing values
```{python}
df_csv.loc[df_csv.isnull().any(axis = 1)]
```

### Find Null Values
+ The number of missing values ​​in each variable
```{python}
df_csv.isnull().sum(axis = 0)
```
### Export data as CSV file
```{python}
df_csv.to_csv("/Users/xudeyu/Downloads/data/311.csv")
```
### Sources
+ data sources:
+ [311_Service_request](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/about_data)
+ references:
+ [ids 24 spring](https://statds.github.io/ids-s24/)
